# Supervised Learning

Models learn from **labeled data**—data that includes both input features and the desired output (label). The goal is to map input features to a target variable.

It’s used for two main types of problems:
1.  **Classification:** Predicting a discrete class label (e.g., spam/not spam).
2.  **Regression:** Predicting a continuous numerical value (e.g., house price).

## Core Algorithms

### Instance-Based
* **[[K-Nearest Neighbors (k-NN)]]**: A non-parametric, lazy learning algorithm based on distance.

### Probabilistic
* **[[Naive Bayes (NB)]]**: A classifier based on Bayes' Theorem and the assumption of feature independence.

### Linear/Non-linear Classification
* **[[Support Vector Machines (SVM)]]**: Finds the optimal hyperplane to maximize the margin.

### Neural Architectures
* **[[Neural Networks]]** (See dedicated course: [[Neural Networks]]): Complex models inspired by the human brain.

### Ensemble Methods
* **Decision Trees & Ensemble Methods**: Includes **Random Forest** (reduces variance/overfitting) and **Gradient Boosting Machines** (reduces bias).